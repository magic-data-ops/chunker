categories:
  - name: cross_context_synthesis
    display_name: "Successfully synthesizes across long context within the legal domain"
    description: >
      Questions requiring the model to synthesize information from multiple
      widely separated passages within California state case law to produce
      a coherent, unified answer that no single passage could provide alone.
    min_hops: 2
    max_hops: 10
    domain_scope: california_state_case_law
    num_turns: 4
    multiturn_scenario: >
      Early turns ask about individual passages or cases in isolation.
      The conversation builds up separate pieces of information from
      different parts of the corpus. The final evaluation question asks
      the model to synthesize these separate pieces into a unified answer
      that no single passage could provide alone.

  - name: long_context_citation
    display_name: "Retrieves information in a long context source and correctly cites its source"
    description: >
      Questions testing whether the model can locate a specific piece of
      information within a large corpus and accurately cite the case name,
      volume, page number, year, or other identifying metadata from the source.
    min_hops: 1
    max_hops: 5
    domain_scope: california_state_case_law
    num_turns: 3
    multiturn_scenario: >
      Early turns ask about content near the target passage, establishing
      the general area of the corpus the user is interested in. The final
      evaluation question requires precise citation of a specific case,
      volume, page, or other metadata.

  - name: hierarchy_comprehension
    display_name: "Ability to comprehend the hierarchy structure of a long text source"
    description: >
      Questions that require understanding the hierarchical organization of
      legal text — e.g., distinguishing majority opinions from dissents,
      headnotes from holdings, procedural posture from substantive rulings,
      or nested statutory references within case opinions.
    min_hops: 1
    max_hops: 8
    domain_scope: california_state_case_law
    num_turns: 3
    multiturn_scenario: >
      Early turns establish the structural context of a legal document —
      discussing one level of the hierarchy (e.g., the majority opinion).
      The final evaluation question asks the model to distinguish or
      relate different structural levels (e.g., majority vs. dissent,
      headnote vs. holding).

  - name: entity_state_tracking
    display_name: "Tracks entity state changes across long, interleaved histories"
    description: >
      Questions requiring the model to track how a legal entity (party, statute,
      property, or legal standard) changes state across multiple interleaved
      passages — e.g., a party's legal status through successive proceedings,
      or a property's chain of title across multiple transactions.
    min_hops: 2
    max_hops: 10
    domain_scope: california_state_case_law
    num_turns: 5
    multiturn_scenario: >
      The conversation tracks an entity across different time points.
      Early turns ask about the entity's initial state or an early
      proceeding. Middle turns ask about intermediate changes. The final
      evaluation question requires the model to describe the full state
      trajectory or identify how the entity's status changed across all
      proceedings discussed in the conversation.

  - name: entity_disambiguation
    display_name: "Disambiguates distinct entities with identical or near-identical names across context"
    description: >
      Questions requiring the reader to distinguish two or more entities sharing
      the same or near-identical name across different cases, contexts, domains,
      or time periods within the California case law corpus.
    min_hops: 1
    max_hops: 10
    domain_scope: california_state_case_law
    num_turns: 5
    multiturn_scenario: >
      The conversation history discusses one entity by name, establishing
      facts about it in a specific context. Then the conversation naturally
      shifts to discuss a different entity sharing the same or similar name
      but in a different context, case, or time period. The final evaluation
      question asks the model to clearly disambiguate between the entities
      discussed throughout the conversation.

  - name: multi_hop_reasoning
    display_name: "Performs multi-hop reasoning across documents that are widely separated in context"
    description: >
      Questions whose complete answer requires synthesizing facts from two or
      more non-adjacent passages that are widely separated in the corpus. No
      single passage is sufficient to answer the question.
    min_hops: 2
    max_hops: 10
    domain_scope: california_state_case_law
    num_turns: 4
    multiturn_scenario: >
      The conversation establishes individual facts step by step. Each
      turn explores a different piece of evidence from a different part
      of the corpus. The final evaluation question requires combining
      all established facts through multi-hop reasoning to reach a
      conclusion that no single passage supports.

  - name: semantic_deduplication
    display_name: "Deduplicates semantically identical information expressed differently across multiple sources"
    description: >
      Questions testing whether the model can identify that two or more passages
      from different cases express the same legal principle, fact, or holding
      using different wording, and produce a deduplicated answer rather than
      treating them as distinct information.
    min_hops: 2
    max_hops: 10
    domain_scope: california_state_case_law
    num_turns: 3
    multiturn_scenario: >
      An early turn presents information from one source using its
      original wording. The conversation then introduces the same
      information from a different source stated differently. The final
      evaluation question asks whether these are the same or different
      principles, or asks the model to produce a single deduplicated
      statement.

  - name: temporal_ordering
    display_name: "Reconstructs accurate temporal ordering from events scattered non-chronologically across context"
    description: >
      Questions requiring the model to reconstruct the correct chronological
      sequence of events (filings, rulings, amendments, transactions) that
      appear out of order across different passages in the corpus.
    min_hops: 2
    max_hops: 10
    domain_scope: california_state_case_law
    num_turns: 4
    multiturn_scenario: >
      The conversation presents events from the corpus in a non-chronological
      order — mixing discussion of earlier and later events across turns.
      The final evaluation question asks the model to reconstruct the
      correct chronological sequence from all events discussed in the
      conversation history.

  - name: domain_scoping
    display_name: "Correctly scopes information to its domain of applicability"
    description: >
      Questions testing whether the model correctly limits a legal principle,
      statute, or ruling to its proper domain of applicability — e.g.,
      distinguishing civil from criminal standards, state from federal
      jurisdiction, or one area of law from another.
    min_hops: 1
    max_hops: 8
    domain_scope: california_state_case_law
    num_turns: 3
    multiturn_scenario: >
      An early turn discusses a legal principle in a general context.
      The conversation then narrows the discussion toward a specific
      domain. The final evaluation question tests whether the model
      correctly scopes the principle to its proper domain of applicability
      rather than overgeneralizing.

  - name: source_prioritization
    display_name: "Prioritizes information sources by recency, authority, or specificity when context contains superseded content"
    description: >
      Questions requiring the model to identify which of multiple conflicting
      or overlapping sources takes precedence based on recency (later case
      overruling earlier), authority (Supreme Court vs. appellate), or
      specificity (narrow holding vs. broad dictum).
    min_hops: 2
    max_hops: 10
    domain_scope: california_state_case_law
    num_turns: 4
    multiturn_scenario: >
      Early turns present information from lower-priority sources (older
      cases, lower courts, broader dicta). Later turns introduce
      higher-priority sources that supersede or narrow the earlier
      information. The final evaluation question asks which source
      takes precedence and why.

  - name: numerical_aggregation
    display_name: "Performs basic mathematical operations (sums, averages, or counts) across all entities in a long context source"
    description: >
      Questions requiring the model to perform arithmetic — counting cases,
      summing damages, averaging time periods, or computing other numerical
      aggregates — across multiple passages scattered throughout the corpus.
    min_hops: 2
    max_hops: 10
    domain_scope: california_state_case_law
    num_turns: 4
    multiturn_scenario: >
      The conversation collects individual numerical facts across turns.
      Each turn discusses a different data point (an amount, a count,
      a date). The final evaluation question asks the model to perform
      arithmetic across all numerical facts established in the
      conversation (sum, average, count, or comparison).

  - name: conflicting_information_synthesis
    display_name: "Synthesizes large amounts of conflicting information presenting a balance of views across multiple viewpoints"
    description: >
      Questions requiring the model to identify and fairly present multiple
      conflicting legal viewpoints, dissenting opinions, or contradictory
      holdings across different cases, synthesizing them into a balanced
      analysis rather than choosing one side.
    min_hops: 2
    max_hops: 10
    domain_scope: california_state_case_law
    num_turns: 5
    multiturn_scenario: >
      The conversation progressively presents conflicting viewpoints.
      Early turns establish one legal position or holding. Middle turns
      introduce a contrasting or contradictory position from a different
      source. The history builds up multiple perspectives. The final
      evaluation question asks the model to synthesize all conflicting
      viewpoints into a balanced analysis.
